{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prkrptr/colab_nbs/blob/main/Week_2_Five_V's_of_Big_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# DAT204M - Week 1: Five V's of Big Data\n",
        "#\n",
        "# This assignment is designed to help you practice basic data processing\n",
        "# in Python, a fundamental skill for working with big data. You will work\n",
        "# with different \"types\" of data and perform simple analysis.\n",
        "#\n",
        "# Remember the five Vs of big data: Volume, Velocity, Veracity, Value, and Variety.\n",
        "# This assignment focuses on Variety, Veracity, and data processing for Value.\n",
        "# ==============================================================================\n",
        "\n",
        "import json\n",
        "import random\n",
        "import uuid\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# --- Part 1: Generating Synthetic Data ---\n",
        "\n",
        "def generate_structured_data(num_records):\n",
        "    \"\"\"\n",
        "    Generates a list of dictionaries simulating structured event data.\n",
        "    \"\"\"\n",
        "    event_types = [\"page_view\", \"click\", \"purchase\"]\n",
        "    records = []\n",
        "    for i in range(num_records):\n",
        "        user_id = random.randint(1000, 2000)\n",
        "        event_type = random.choice(event_types)\n",
        "        timestamp = (datetime.utcnow() - timedelta(seconds=random.randint(0, 3600))).isoformat() + \"Z\"\n",
        "        records.append({\"user_id\": user_id, \"event_type\": event_type, \"timestamp\": timestamp})\n",
        "    return records\n",
        "\n",
        "def generate_semi_structured_data(num_records):\n",
        "    \"\"\"\n",
        "    Generates a list of JSON-like strings.\n",
        "    Intentionally includes some malformed data to test Veracity handling.\n",
        "    \"\"\"\n",
        "    content_snippets = [\n",
        "        \"The quick brown fox jumped over the lazy dog.\",\n",
        "        \"Python is a powerful programming language.\",\n",
        "        \"Big data is characterized by the 5 Vs.\",\n",
        "        \"Data can be structured, unstructured, or semi-structured.\",\n",
        "        \"The big data ecosystem is complex.\",\n",
        "        \"DataOps and governance are important.\",\n",
        "        \"AI technologies are used to analyze data.\",\n",
        "    ]\n",
        "    tags_list = [\n",
        "        [\"animal\", \"story\"],\n",
        "        [\"programming\", \"python\"],\n",
        "        [\"big data\", \"lecture\", \"5vs\"],\n",
        "        [\"data\", \"types\"],\n",
        "        [\"big data\", \"ecosystem\", \"trends\"],\n",
        "        [\"data\", \"governance\", \"trends\"],\n",
        "        [\"AI\", \"analytics\", \"learning\"],\n",
        "    ]\n",
        "\n",
        "    records = []\n",
        "    for i in range(num_records):\n",
        "        if i % 10 == 0:  # Introduce a malformed record every 10 records\n",
        "            records.append('This is not valid JSON.')\n",
        "            continue\n",
        "\n",
        "        doc_id = str(uuid.uuid4())\n",
        "        content = random.choice(content_snippets)\n",
        "        tags = random.choice(tags_list)\n",
        "        records.append(json.dumps({\"id\": doc_id, \"content\": content, \"tags\": tags}))\n",
        "    return records\n",
        "\n",
        "def generate_unstructured_data(num_records):\n",
        "    \"\"\"\n",
        "    Generates a list of simple sentences.\n",
        "    \"\"\"\n",
        "    lecture_keywords = [\"data\", \"structured\", \"unstructured\", \"semi-structured\", \"volume\", \"velocity\", \"variety\", \"mining\", \"DataOps\", \"learning\", \"AI\", \"analytics\", \"trends\"]\n",
        "    sentences = []\n",
        "    for _ in range(num_records):\n",
        "        num_keywords = random.randint(1, 3)\n",
        "        sentence_parts = [random.choice(lecture_keywords) for _ in range(num_keywords)]\n",
        "        # Add some filler words to make it more like a sentence\n",
        "        filler_words = [\"is\", \"the\", \"a\", \"and\", \"or\", \"in\", \"with\", \"from\"]\n",
        "        random.shuffle(filler_words)\n",
        "        combined_words = []\n",
        "        for word in sentence_parts:\n",
        "            combined_words.append(word)\n",
        "            if random.random() > 0.5: # Add a filler word sometimes\n",
        "                combined_words.append(random.choice(filler_words))\n",
        "\n",
        "        sentence = \" \".join(combined_words)\n",
        "        sentence = sentence.capitalize() + \".\"\n",
        "        sentences.append(sentence)\n",
        "    return sentences\n",
        "\n",
        "# --- Part 2: Assignment Tasks ---\n",
        "# Note: These functions are the same as before and will now operate on much larger datasets.\n",
        "\n",
        "def count_user_events(data):\n",
        "    \"\"\"\n",
        "    Counts 'click' and 'page_view' events for each user.\n",
        "    Returns a dictionary with user_id as key and event counts as value.\n",
        "    Example output: {101: {'page_view': 1, 'click': 2}}\n",
        "    \"\"\"\n",
        "    user_event_counts = {}\n",
        "    for record in data:\n",
        "        user_id = record['user_id']\n",
        "        event_type = record['event_type']\n",
        "        if event_type in ['click', 'page_view']:\n",
        "            if user_id not in user_event_counts:\n",
        "                user_event_counts[user_id] = {'page_view': 0, 'click': 0}\n",
        "            user_event_counts[user_id][event_type] += 1\n",
        "    return user_event_counts\n",
        "\n",
        "def find_multi_tagged_documents(data):\n",
        "    \"\"\"\n",
        "    Safely parses JSON strings and finds documents that have more than one tag.\n",
        "    Returns a list of dictionaries for each valid document found.\n",
        "    \"\"\"\n",
        "    valid_documents = []\n",
        "    for record_str in data:\n",
        "        try:\n",
        "            record = json.loads(record_str)\n",
        "            if len(record.get('tags', [])) > 1:\n",
        "                valid_documents.append({\"id\": record['id'], \"tags\": record['tags']})\n",
        "        except json.JSONDecodeError:\n",
        "            print(f\"Skipping malformed JSON record: '{record_str}'\")\n",
        "    return valid_documents\n",
        "\n",
        "def find_most_frequent_keyword(data):\n",
        "    \"\"\"\n",
        "    Finds the most frequent keyword from the lecture in the unstructured data.\n",
        "    Returns a tuple of the keyword and its count.\n",
        "    Example: ('data', 3)\n",
        "    \"\"\"\n",
        "    keywords = [\"data\", \"structured\", \"unstructured\", \"semi-structured\", \"volume\", \"velocity\", \"variety\", \"mining\", \"DataOps\", \"learning\", \"AI\", \"analytics\"]\n",
        "    keyword_counts = {keyword: 0 for keyword in keywords}\n",
        "\n",
        "    for sentence in data:\n",
        "        words = sentence.lower().split()\n",
        "        for word in words:\n",
        "            word = word.replace(\",\", \"\").replace(\".\", \"\")\n",
        "            if word in keyword_counts:\n",
        "                keyword_counts[word] += 1\n",
        "\n",
        "    most_frequent = (\"\", 0)\n",
        "    for keyword, count in keyword_counts.items():\n",
        "        if count > most_frequent[1]:\n",
        "            most_frequent = (keyword, count)\n",
        "\n",
        "    return most_frequent\n",
        "\n",
        "# --- Part 3: Running the Assignment ---\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # --- Instructions for students ---\n",
        "    print(\"--- Big Data Programming Assignment ---\")\n",
        "    print(\"The datasets are now being generated synthetically.\")\n",
        "    print(\"This simulates the 'Volume' characteristic of big data.\")\n",
        "\n",
        "    # Generate large datasets (e.g., 1000 records each)\n",
        "    NUM_RECORDS = 1000\n",
        "    structured_data = generate_structured_data(NUM_RECORDS)\n",
        "    semi_structured_data = generate_semi_structured_data(NUM_RECORDS)\n",
        "    unstructured_data = generate_unstructured_data(NUM_RECORDS)\n",
        "\n",
        "    print(f\"\\nSuccessfully generated {len(structured_data)} structured records.\")\n",
        "    print(f\"Successfully generated {len(semi_structured_data)} semi-structured records.\")\n",
        "    print(f\"Successfully generated {len(unstructured_data)} unstructured records.\")\n",
        "\n",
        "    print(\"\\n--- Your Results ---\")\n",
        "\n",
        "    # Run Task 1 and print the result.\n",
        "    user_event_counts = count_user_events(structured_data)\n",
        "    print(\"Task 1: User event counts for the first 5 users:\")\n",
        "    # Print a small subset to avoid overwhelming the output\n",
        "    for user_id, counts in list(user_event_counts.items())[:5]:\n",
        "        print(f\"  - User {user_id}: {counts}\")\n",
        "    print(f\"(Total unique users: {len(user_event_counts)})\")\n",
        "\n",
        "    # Run Task 2 and print the result.\n",
        "    multi_tagged_docs = find_multi_tagged_documents(semi_structured_data)\n",
        "    print(\"\\nTask 2: Valid documents with multiple tags (first 5 found):\")\n",
        "    for doc in multi_tagged_docs[:5]:\n",
        "        print(f\"  - Document ID: {doc['id']}, Tags: {doc['tags']}\")\n",
        "    print(f\"(Total valid documents found: {len(multi_tagged_docs)})\")\n",
        "\n",
        "    # Run Task 3 and print the result.\n",
        "    top_keyword, keyword_count = find_most_frequent_keyword(unstructured_data)\n",
        "    print(f\"\\nTask 3: The most frequent keyword is '{top_keyword}' with a count of {keyword_count}.\")\n",
        "\n",
        "    print(\"\\n--- End of Assignment ---\")\n",
        "    print(\"Feel free to add more test cases or explore the data further!\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "ZydApuP4Bla-"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}